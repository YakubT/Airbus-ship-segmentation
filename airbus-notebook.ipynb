{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-02T13:23:11.067007Z",
     "iopub.status.busy": "2023-12-02T13:23:11.066714Z",
     "iopub.status.idle": "2023-12-02T13:23:11.316404Z",
     "shell.execute_reply": "2023-12-02T13:23:11.315500Z",
     "shell.execute_reply.started": "2023-12-02T13:23:11.066980Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 768, 768, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 768, 768, 128)        3584      ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 768, 768, 128)        147584    ['conv2d_33[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 384, 384, 128)        0         ['conv2d_34[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 384, 384, 256)        295168    ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 384, 384, 256)        590080    ['conv2d_35[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 192, 192, 256)        0         ['conv2d_36[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 192, 192, 512)        1180160   ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (None, 192, 192, 512)        2359808   ['conv2d_37[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSamplin  (None, 384, 384, 512)        0         ['conv2d_38[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 384, 384, 768)        0         ['conv2d_36[0][0]',           \n",
      " )                                                                   'up_sampling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (None, 384, 384, 256)        1769728   ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (None, 384, 384, 256)        590080    ['conv2d_39[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSamplin  (None, 768, 768, 256)        0         ['conv2d_40[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 768, 768, 384)        0         ['conv2d_34[0][0]',           \n",
      " )                                                                   'up_sampling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (None, 768, 768, 256)        884992    ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (None, 768, 768, 256)        590080    ['conv2d_41[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (None, 768, 768, 1)          257       ['conv2d_42[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8411521 (32.09 MB)\n",
      "Trainable params: 8411521 (32.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "def extract_channel(mask, channel_index):\n",
    "    # Assuming 'mask' is a tensor with shape (height, width, channels)\n",
    "    extracted_channel = mask[:, :, channel_index+1]\n",
    "\n",
    "    # Add an extra dimension to make it (height, width, 1)\n",
    "    extracted_channel = tf.expand_dims(extracted_channel, axis=-1)\n",
    "\n",
    "    return extracted_channel\n",
    "\n",
    "def load_and_preprocess_image(image_path, mask_path):\n",
    "    image_path = image_path.numpy().decode('utf-8')\n",
    "    mask_path = mask_path.numpy().decode('utf-8')\n",
    "    # Load and preprocess image\n",
    "    image = load_img(image_path, target_size=(768, 768))\n",
    "    image = img_to_array(image)/255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Load and preprocess mask\n",
    "    mask = load_img(mask_path,color_mode='grayscale',  target_size=(768, 768))\n",
    "    mask = img_to_array(mask)/255.0  # Normalize to [0, 1]\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "def _parse_function(image_path, mask_path):\n",
    "   # print(mask_path)\n",
    "    image_string = tf.io.read_file(image_path)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    #image_decoded = tf.image.resize(image_decoded, [128, 128])\n",
    "    image = tf.cast(image_decoded, tf.float32)/255.0\n",
    "    mask_string = tf.io.read_file(mask_path)\n",
    "    mask_decoded = tf.image.decode_jpeg(mask_string, channels=3)\n",
    "    #plt.imshow(mask_decoded)\n",
    "    #plt.show()\n",
    "    mask_decoded = tf.image.rgb_to_grayscale(mask_decoded)\n",
    "    #print(mask_decoded.numpy().tolist())\n",
    "    #mask_decoded = tf.image.resize(mask_decoded, [128, 128])\n",
    "   # plt.imshow(mask_decoded)\n",
    "    #plt.show()\n",
    "   # mask_decoded = extract_channel(mask_decoded,0)\n",
    "    mask = tf.cast(mask_decoded, tf.float32)//255\n",
    "    #print()\n",
    "    #print(mask.numpy().tolist())\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "#Define the U-Net architecture\n",
    "def unet_model(input_shape=(768, 768, 3)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "   # Encoder\n",
    "    conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    # Bottom\n",
    "    conv3 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    up1 = UpSampling2D((2, 2))(conv3)\n",
    "    concat1 = concatenate([conv2, up1], axis=-1)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(concat1)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(conv4)\n",
    "    concat2 = concatenate([conv1, up2], axis=-1)\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(concat2)\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv5)  # Assuming binary segmentation\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# def unet_model(input_shape=(768, 768, 3)):\n",
    "#     inputs = Input(shape=input_shape)\n",
    "\n",
    "#     # Encoder\n",
    "#     conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(inputs)\n",
    "#     conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv1)\n",
    "#     pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "#     conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "#     conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "#     pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "#     # Bottleneck\n",
    "#     conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool2)\n",
    "#     conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "#     # Decoder\n",
    "#     up1 = UpSampling2D((2, 2))(conv3)\n",
    "#     concat1 = concatenate([conv2, up1], axis=-1)\n",
    "#     conv4 = Conv2D(16, (3, 3), activation='relu', padding='same')(concat1)\n",
    "#     conv4 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "#     up2 = UpSampling2D((2, 2))(conv4)\n",
    "#     concat2 = concatenate([conv1, up2], axis=-1)\n",
    "#     conv5 = Conv2D(8, (3, 3), activation='relu', padding='same')(concat2)\n",
    "#     conv5 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "#     outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv5)  # Assuming binary segmentation\n",
    "\n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "#     return model\n",
    "\n",
    "# def unet_model(input_shape=(768, 768, 3)):\n",
    "#     inputs = Input(shape=input_shape)\n",
    "\n",
    "#     # Encoder\n",
    "#     conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
    "#     conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv1)\n",
    "#     pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "#     # Bottleneck\n",
    "#     conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool1)\n",
    "#     conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv2)\n",
    "\n",
    "#     # Decoder\n",
    "#     up1 = UpSampling2D((2, 2))(conv2)\n",
    "#     concat1 = concatenate([conv1, up1], axis=-1)\n",
    "#     conv3 = Conv2D(16,(3, 3), activation='relu', padding='same')(concat1)\n",
    "#     conv3 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "#     outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv3)\n",
    "\n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "#     return model\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "#     #print(y_true.numpy)\n",
    "#     #print(y_pred.numpy())\n",
    "#     y_true_f = tf.cast(K.flatten(y_true),'float32')\n",
    "#     y_pred_f = tf.cast(K.flatten(y_pred), 'float32')\n",
    "#     #tf.keras.backend.clear_session()\n",
    "#     y_pred_f = tf.where(y_pred_f < threshold, 0.0, y_pred_f )\n",
    "#     #tf.keras.backend.clear_session()\n",
    "#     y_pred_f = tf.where(y_pred_f >= threshold, 1.0, y_pred_f )\n",
    "#     #print(y_pred_f.shape)\n",
    "#     #print(y_true_f.shape)\n",
    "#     #print(y_true.numpy().tolist())\n",
    "#     #y_pred_f = tf.round(y_pred_f)\n",
    "#     intersection = K.sum(y_true_f * y_pred_f)\n",
    "#     #print(intersection)\n",
    "#     #print(intersection.numpy())\n",
    "#     #print(intersection.numpy())\n",
    "#     dice = (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "#     return dice\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return dice\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "path = '.'\n",
    "# train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "#     path+'/processed_data_train/train',\n",
    "#     image_size=(768, 768),  # Set the desired image size\n",
    "#     seed=123,  # Set a seed for reproducibility (optional)\n",
    "#     labels=\"inferred\",\n",
    "#     color_mode='rgb',\n",
    "#     label_mode=None,  # No labels as we are loading masks\n",
    "#     image_folder='images',\n",
    "#     mask_folder='masks',\n",
    "#     interpolation=\"nearest\"\n",
    "# )\n",
    "\n",
    "# validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "#     path+'/processed_data_train/validation',\n",
    "#     image_size=(768, 768),  # Set the desired image size\n",
    "#     seed=123,  # Set a seed for reproducibility (optional)\n",
    "#     labels=\"inferred\",\n",
    "#     color_mode='rgb',\n",
    "#     label_mode=None,  # No labels as we are loading masks\n",
    "#     image_folder='images',\n",
    "#     mask_folder='masks',\n",
    "#     interpolation=\"nearest\"\n",
    "# )\n",
    "\n",
    "def getDs(path_img,path_masks,cnt):\n",
    "    \n",
    "    image_paths = []\n",
    "    mask_paths = []\n",
    "    for i in range(1,cnt+1):\n",
    "        image_paths.append(path_img+'/image'+str(i)+'.jpg')\n",
    "        mask_paths.append(path_masks+'/mask'+str(i)+'.jpg')\n",
    "    \n",
    "    # Create a dataset from slices\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
    "\n",
    "    # Map the load_and_preprocess_image function to load and preprocess each image and mask\n",
    "    dataset = dataset.map(lambda x, y: tf.py_function(_parse_function, [x, y], [tf.float32, tf.float32]))\n",
    "    \n",
    "    # Shuffle and batch the dataset\n",
    "    dataset = dataset.shuffle(buffer_size=len(image_paths)).batch(batch_size=2).prefetch(buffer_size=tf.data.AUTOTUNE) \n",
    "    return dataset\n",
    "\n",
    "# Instantiate the model\n",
    "model = unet_model()\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-5, clipvalue=1.0)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,  loss=dice_coef_loss)\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = getDs(path+'/processed_data_train/train/images',path+'/processed_data_train/train/masks',100)\n",
    "\n",
    "#_parse_function(path+'/processed_data_train/train/images/image2.jpg',path+'/processed_data_train/train/masks/mask2.jpg')\n",
    "\n",
    "validation_dataset = getDs(path+'/processed_data_train/validation/images',path+'/processed_data_train/validation/masks',25)\n",
    "#train\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T13:23:14.300125Z",
     "iopub.status.busy": "2023-12-02T13:23:14.299682Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH = 2\n",
    "STEPS_PER_EPOCH = 1000//BATCH\n",
    "VALIDATION_STEPS = 250//BATCH\n",
    "\n",
    "history = model.fit(train_dataset,validation_data = (validation_dataset),epochs=10)\n",
    "model.save('./model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 868324,
     "sourceId": 9988,
     "sourceType": "competition"
    },
    {
     "datasetId": 4090484,
     "sourceId": 7097101,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4090507,
     "sourceId": 7097127,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4090627,
     "sourceId": 7097278,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
